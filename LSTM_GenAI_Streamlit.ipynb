{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14Rm6J2C0WPA",
        "outputId": "af5a38d0-1a39-44d4-ae30-a8b4b2d7be8c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.35.0-py2.py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.6.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.35.0 watchdog-4.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7FWMBYG0iv0",
        "outputId": "3e8ed1fe-2825-47fb-a27c-c163d288ed22"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.34.0-py3-none-any.whl (325 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/325.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m317.4/325.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EXdAZfw0wkm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7196ad3c-794e-4cda-a481-bcdb0e311d16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5743/5743 [==============================] - 312s 53ms/step - loss: 1.0180 - accuracy: 0.5035 - val_loss: 0.9968 - val_accuracy: 0.5216\n",
            "Epoch 2/10\n",
            "5743/5743 [==============================] - 287s 50ms/step - loss: 0.9973 - accuracy: 0.5198 - val_loss: 0.9870 - val_accuracy: 0.5260\n",
            "Epoch 3/10\n",
            "5743/5743 [==============================] - 305s 53ms/step - loss: 1.0066 - accuracy: 0.5145 - val_loss: 1.0472 - val_accuracy: 0.4915\n",
            "Epoch 4/10\n",
            "5743/5743 [==============================] - 315s 55ms/step - loss: 1.0289 - accuracy: 0.4980 - val_loss: 1.0175 - val_accuracy: 0.5025\n",
            "Epoch 5/10\n",
            "5743/5743 [==============================] - 311s 54ms/step - loss: 1.0073 - accuracy: 0.5140 - val_loss: 0.9981 - val_accuracy: 0.5212\n",
            "Epoch 6/10\n",
            "5743/5743 [==============================] - 309s 54ms/step - loss: 0.9990 - accuracy: 0.5208 - val_loss: 1.0034 - val_accuracy: 0.5094\n",
            "Epoch 7/10\n",
            "5743/5743 [==============================] - 315s 55ms/step - loss: 0.9907 - accuracy: 0.5248 - val_loss: 1.0347 - val_accuracy: 0.4809\n",
            "Epoch 8/10\n",
            "5743/5743 [==============================] - 313s 54ms/step - loss: 0.9819 - accuracy: 0.5285 - val_loss: 0.9823 - val_accuracy: 0.5283\n",
            "Epoch 9/10\n",
            "5743/5743 [==============================] - 317s 55ms/step - loss: 0.9751 - accuracy: 0.5325 - val_loss: 0.9715 - val_accuracy: 0.5378\n",
            "Epoch 10/10\n",
            "5743/5743 [==============================] - 321s 56ms/step - loss: 0.9677 - accuracy: 0.5386 - val_loss: 0.9568 - val_accuracy: 0.5429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-06-15 17:49:59.476 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2024-06-15 17:49:59.478 Session state does not function when running a script without `streamlit run`\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import openai\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input, Bidirectional, BatchNormalization, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/adi31891/capstone-C241-PR565/f8a43716e964aa3bc19b1de1d1947aa550dd6bb9/data/capstone_new_dataset.csv\")\n",
        "\n",
        "# Extract text and labels\n",
        "texts = data['text'].astype(str).values\n",
        "labels = data['sentiment'].astype(str).values\n",
        "\n",
        "# Encode labels to integers\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# One-hot encode the integer labels\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded_labels = integer_encoded_labels.reshape(len(integer_encoded_labels), 1)\n",
        "onehot_encoded_labels = onehot_encoder.fit_transform(integer_encoded_labels)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, onehot_encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load the Universal Sentence Encoder\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "# Function to create embeddings for a given list of texts in batches\n",
        "def get_embeddings_in_batches(texts, batch_size=256):\n",
        "    embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "        batch_embeddings = embed(batch_texts)\n",
        "        embeddings.append(batch_embeddings)\n",
        "    return tf.concat(embeddings, axis=0)\n",
        "\n",
        "# Create embeddings for train and test sets in batches\n",
        "train_embeddings = get_embeddings_in_batches(X_train)\n",
        "test_embeddings = get_embeddings_in_batches(X_test)\n",
        "\n",
        "# Define the LSTM model\n",
        "input_shape = train_embeddings.shape[1]\n",
        "inputs = Input(shape=(input_shape,), dtype=tf.float32)\n",
        "x = tf.expand_dims(inputs, -1)\n",
        "x = Bidirectional(LSTM(64, return_sequences = True))(x)\n",
        "x = LSTM(32)(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = BatchNormalization()(x)\n",
        "outputs = Dense(3, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_embeddings, y_train, epochs=10, batch_size=32, validation_data=(test_embeddings, y_test))\n",
        "\n",
        "# Function to predict sentiment\n",
        "def predict_sentiment(text):\n",
        "    embedding = embed([text])\n",
        "    prediction = model.predict(embedding)\n",
        "    sentiment_index = tf.argmax(prediction[0]).numpy()\n",
        "    sentiment = label_encoder.inverse_transform([sentiment_index])[0]\n",
        "    return sentiment\n",
        "\n",
        "# Function to generate a response based on sentiment\n",
        "def generate_response(sentiment):\n",
        "    if sentiment == 'good':\n",
        "        return \"I'm glad to hear that! Keep up the positive vibes.\"\n",
        "    elif sentiment == 'bad':\n",
        "        return \"That sounds not good. I'm sorry to hear that. Remember, it's okay to feel this way sometimes. Can I help you with something?\"\n",
        "    elif sentiment == 'neutral':\n",
        "        return \"Thanks for sharing your feelings with me. Anything I can help you with?\"\n",
        "    else:\n",
        "        return \"Thanks for sharing your feelings.\"\n",
        "\n",
        "# Streamlit interface\n",
        "st.title(\"Chatbot with Sentiment Analysis\")\n",
        "\n",
        "if 'messages' not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "for msg in st.session_state.messages:\n",
        "    st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n",
        "\n",
        "if prompt := st.chat_input(\"Your message...\"):\n",
        "    if not openai_api_key:\n",
        "        st.info(\"Please add your OpenAI API key to continue.\")\n",
        "        st.stop()\n",
        "\n",
        "    client = OpenAI(api_key=openai_api_key)\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    st.chat_message(\"user\").write(prompt)\n",
        "\n",
        "    # Predict sentiment and generate a response\n",
        "    predicted_sentiment = predict_sentiment(prompt)\n",
        "    sentiment_response = generate_response(predicted_sentiment)\n",
        "\n",
        "    # Use OpenAI to generate a response\n",
        "    response = client.chat.completions.create(model=\"gpt-3.5-turbo\", messages=st.session_state.messages)\n",
        "    msg = response.choices[0].message.content\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": msg})\n",
        "\n",
        "    st.chat_message(\"assistant\").write(f\"Sentiment Analysis: {predicted_sentiment}\\n{sentiment_response}\\n\\n{msg}\")\n"
      ]
    }
  ]
}